import torch
import torchvision
import torchvision.transforms as transforms

from dataset.fake_human.abstract_fake_human_dataset import AbstractFakeHumanDataset


# nn's dataset
class Cifar10FakeHumanDataset(AbstractFakeHumanDataset):

    def __init__(self, x_labeled, y_labeled, total_labeled_samples_size=0, total_unlabeled_samples_size=0, metric_size=0, batch_size=32):
        self.batch_size = batch_size
        if x_labeled is None or y_labeled is None:
            transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])
            dataset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)
            x_labeled = []
            y_labeled = []
            x_unlabeled = []
            y_unlabeled = []
            x_metric = []
            y_metric = []
            for i, data in enumerate(dataset):
                if i < total_labeled_samples_size:
                    image, label = data
                    x_labeled.append(image)
                    y_labeled.append(label)

                elif total_labeled_samples_size < i < total_labeled_samples_size + total_unlabeled_samples_size:
                    image, label = data
                    x_unlabeled.append(torch.reshape(image, (1, 3, 32, 32)))
                    print(label)
                    print(type(label)) #TODO mettere un vettore com l'indoice massimo
                    y_unlabeled.append(label)

                elif total_labeled_samples_size + total_unlabeled_samples_size < i < total_labeled_samples_size + total_unlabeled_samples_size + metric_size:
                    image, label = data
                    x_metric.append(torch.reshape(image, (1, 3, 32, 32)))
                    y_metric.append(label)

            super().__init__(x_labeled, y_labeled, x_unlabeled, y_unlabeled, x_metric, y_metric, batch_size)

        else:
            super().__init__(x_labeled, y_labeled, batch_size=batch_size)
