import numpy
import torch
import torchvision
import torchvision.transforms as transforms

from dataset.fake_human.abstract_fake_human_dataset import AbstractFakeHumanDataset


# nn's dataset
class Cifar10FakeHumanDataset(AbstractFakeHumanDataset):

    def __init__(self, x_labeled, y_labeled, total_labeled_samples_size=0, total_unlabeled_samples_size=0, metric_size=0, batch_size=32):
        self.batch_size = batch_size
        if x_labeled is None or y_labeled is None:
            transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])
            dataset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)
            x_labeled = []
            y_labeled = []
            x_unlabeled = []
            y_unlabeled = []
            x_metric = []
            y_metric = []
            for i, data in enumerate(dataset):
                image, label = data
                if i < total_labeled_samples_size:
                    x_labeled.append(image)
                    y_labeled.append(label)

                elif total_labeled_samples_size < i < total_labeled_samples_size + total_unlabeled_samples_size:
                    x_unlabeled.append(torch.reshape(image, (1, 3, 32, 32)))
                    y_unlabeled.append(torch.from_numpy(numpy.array([label])))

                elif total_labeled_samples_size + total_unlabeled_samples_size < i < total_labeled_samples_size + total_unlabeled_samples_size + metric_size:
                    x_metric.append(image)
                    y_metric.append(label)

            super().__init__(x_labeled, y_labeled, x_unlabeled, y_unlabeled, x_metric, y_metric, batch_size)

        else:
            x = []
            y = []
            for i in range(len(x_labeled)):
                x.append(torch.reshape(x_labeled[i], (3, 32, 32)))
                y.append(y_labeled[i][0])

            super().__init__(x, y, batch_size=batch_size)
