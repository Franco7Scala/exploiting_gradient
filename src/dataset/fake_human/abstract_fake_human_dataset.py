import torch

from torch.utils.data import Dataset, DataLoader


class AbstractFakeHumanDataset(Dataset):

    def __init__(self, inputs, outputs, batch_size, unlabeled_elements, x_metric, y_metric):
        # base dataset
        self.x = inputs
        self.y = outputs
        self.batch_size = batch_size
        # human
        self.unlabeled_elements = unlabeled_elements
        # for metrics
        self.x_metric = x_metric
        self.y_metric = y_metric

    def __getitem__(self, index):
        return {"x": self.x[index], "y": self.y[index]}

    def __len__(self):
        if type(self.x) is list:
            return len(self.x)

        else:
            return self.x.shape[0]

    def get_dataloader(self):
        return DataLoader(self, batch_size=self.batch_size)

    def get_metrics_dataloader(self):
        return DataLoader(AbstractFakeHumanDataset(self.x_metric, self.y_metric, self.batch_size), batch_size=self.batch_size)

    def get_random_labeled_samples(self, quantity):
        x_popped = []
        y_popped = []
        taken = 0
        for key in self.unlabeled_elements.keys():
            x_popped.append(key)
            y_popped.append(self.unlabeled_elements[key])
            taken += 1
            if taken >= quantity:
                break

        for key in x_popped:
            self.unlabeled_elements.pop(key)

        return x_popped, y_popped

    def get_all_unlabeled_samples(self):
        return list(self.unlabeled_elements.keys())

    def annotate(self, x_to_label):
        x_popped = []
        y_popped = []
        for key in x_to_label:
            x_popped.append(key)
            y_popped.append(self.unlabeled_elements.pop(key))

        return x_popped, y_popped
