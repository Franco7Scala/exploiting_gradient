from torch.utils.data import Dataset, DataLoader


class AbstractFakeHumanDataset(Dataset):

    def __init__(self, x_labeled, y_labeled, x_unlabeled=[], y_unlabeled=[], x_metric=[], y_metric=[], batch_size=32):
        # base dataset
        self.x = x_labeled
        self.y = y_labeled
        self.batch_size = batch_size
        # human
        if len(x_unlabeled) != 0 and len(y_unlabeled) != 0:
            iterator = zip(x_unlabeled, y_unlabeled)
            self.unlabeled_elements = dict(iterator)

        # for metrics
        self.x_metric = x_metric
        self.y_metric = y_metric

    def __getitem__(self, index):
        return {"x": self.x[index], "y": self.y[index]}

    def __len__(self):
        if type(self.x) is list:
            return len(self.x)

        else:
            return self.x.shape[0]

    def get_dataloader(self):
        return DataLoader(self, batch_size=self.batch_size)

    def get_metrics_dataloader(self):
        return DataLoader(AbstractFakeHumanDataset(self.x_metric, self.y_metric, batch_size=self.batch_size), batch_size=self.batch_size)

    def get_random_labeled_samples(self, quantity):
        x_popped = []
        y_popped = []
        taken = 0
        for key in self.unlabeled_elements.keys():
            x_popped.append(key)
            print(self.unlabeled_elements[key])
            print(type(self.unlabeled_elements[key]))
            y_popped.append(self.unlabeled_elements[key])
            taken += 1
            if taken >= quantity:
                break

        for key in x_popped:
            self.unlabeled_elements.pop(key)

        return x_popped, y_popped

    def get_all_unlabeled_samples(self):
        return list(self.unlabeled_elements.keys())

    def annotate(self, x_to_label):
        x_popped = []
        y_popped = []
        for key in x_to_label:
            x_popped.append(key)
            y_popped.append(self.unlabeled_elements.pop(key))

        return x_popped, y_popped
