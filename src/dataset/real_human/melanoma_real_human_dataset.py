import torch
import pandas
import random
import numpy

import PIL.Image
from dataset.abstract_human_dataset import AbstractHumanDataset
from torch.utils.data.dataloader import DataLoader
from torchvision.transforms import transforms


class MelanomaRealHumanDataset(AbstractHumanDataset):

    def __init__(self, base_path, delegate, batch_size=32):
        self.delegate = delegate
        self.batch_size = batch_size
        self.base_path = base_path
        dataset_train = pandas.read_csv("{}train.csv".format(self.base_path), usecols=["image_name", "target"])
        dataset_test = pandas.read_csv("{}test.csv".format(self.base_path), usecols=["image_name", "target"])
        dataset_unlabeled = pandas.read_csv("{}unlabeled.csv".format(self.base_path), usecols=["image_name"])
        x_labeled = []
        y_labeled = []
        x_metric = []
        y_metric = []
        x_unlabeled = []
        y_unlabeled = []
        for value in dataset_train.iterrows():
            x_labeled.append(value[1][0])
            y_labeled.append(value[1][1])

        for value in dataset_test.iterrows():
            x_metric.append(value[1][0])
            y_metric.append(value[1][1])

        for value in dataset_unlabeled.iterrows():
            x_unlabeled.append(value[1][0])
            y_unlabeled.append(0)

        super().__init__(x_labeled, y_labeled, x_unlabeled, y_unlabeled, x_metric, y_metric, batch_size)

    def __getitem__(self, index):
        return {"x": self._extract_image(self.x[index]), "y": self.y[index]}

    def annotate(self, x_to_label):
        x_annotated = []
        y_annotated = []
        for key in x_to_label:
            x_annotated.append(key)
            y_annotated.append(self.delegate.annotate(key))

        return x_annotated, y_annotated

    def _extract_image(self, name_image):
        image = PIL.Image.open(open("{}jpeg/train/{}.jpg".format(self.base_path, name_image), "rb"))
        resized = image.resize((512, 512))
        tensored = transforms.ToTensor()(resized).unsqueeze_(0)
        return torch.reshape(tensored, (3, 512, 512))

    def get_metrics_dataloader(self):
        dataset = MelanomaRealHumanDataset(self.base_path, self.delegate, self.batch_size)
        dataset.add_samples(self.x_metric, self.y_metric)
        return DataLoader(dataset, batch_size=self.batch_size)

    def add_samples(self, x, y):
        reshaped_x = []
        reshaped_y = []
        for i in range(len(x)):
            reshaped_x.append(x[i])
            reshaped_y.append(y[i])

        super().add_samples(reshaped_x, reshaped_y)

    def convert_sample(self, x, y=None):
        if isinstance(x, list):
            images = []
            targets = []
            for i in range(len(x)):
                image = self._extract_image(x[i])
                image = torch.reshape(image, (1, 3, 512, 512))
                images.append(image)
                if y is not None:
                    target = torch.tensor(y[i]).to(torch.float32)
                    targets.append(target)

            return images, targets

        else:
            return torch.reshape(self._extract_image(x), (1, 3, 512, 512)), torch.tensor(y).to(torch.float32)
