import torch
import os
import pandas
import numpy
import PIL.Image

from dataset.abstract_human_dataset import AbstractHumanDataset
from torch.utils.data.dataloader import DataLoader
from torchvision.transforms import transforms


_delegate = None
_file_dataset_annotated = None

class MelanomaRealHumanDataset(AbstractHumanDataset):

    def __init__(self, base_path, delegate, batch_size=32):
        global _delegate
        _delegate = delegate
        self.batch_size = batch_size
        self.base_path = base_path
        dataset_train = pandas.read_csv("{}/train.csv".format(self.base_path), usecols=["image_name", "target"])
        dataset_test = pandas.read_csv("{}/test.csv".format(self.base_path), usecols=["image_name", "target"])
        dataset_unlabeled = pandas.read_csv("{}/unlabeled.csv".format(self.base_path), usecols=["image_name"])
        self.path_just_annotated = "{}/annotated.csv".format(self.base_path)
        global _file_dataset_annotated
        yet_created = os.path.isfile(self.path_just_annotated)
        if not yet_created:
            _file_dataset_annotated = open(self.path_just_annotated, "w+")
            _file_dataset_annotated.write("{},{}\n".format("image_name", "target"))
            _file_dataset_annotated.close()

        x_labeled = []
        y_labeled = []
        x_metric = []
        y_metric = []
        x_unlabeled = []
        y_unlabeled = []
        for value in dataset_train.iterrows():
            x_labeled.append(value[1][0])
            y_labeled.append(numpy.array([0, 1]) if value[1][1] == 0 else numpy.array([1, 0]))

        for value in dataset_test.iterrows():
            x_metric.append(value[1][0])
            y_metric.append(numpy.array([0, 1]) if value[1][1] == 0 else numpy.array([1, 0]))

        for value in dataset_unlabeled.iterrows():
            x_unlabeled.append(value[1][0])
            y_unlabeled.append([0, 0])

        super().__init__(x_labeled, y_labeled, x_unlabeled, y_unlabeled, x_metric, y_metric, batch_size)

    def __getitem__(self, index):
        return {"x": self._extract_image(self.x[index]), "y": self.y[index]}

    def annotate(self, x_to_label):
        x_annotated = []
        y_annotated = []
        for key in x_to_label:
            current_x = key
            current_y = _delegate.annotate("{}/jpeg/train/{}.jpg".format(self.base_path, key))
            x_annotated.append(key)
            y_annotated.append(current_y)
            global _file_dataset_annotated
            _file_dataset_annotated = open(self.path_just_annotated, "a")
            _file_dataset_annotated.write("{},{}\n".format(current_x, current_y[1]))
            _file_dataset_annotated.close()

        return x_annotated, y_annotated

    def _extract_image(self, name_image):
        image = PIL.Image.open(open("{}/jpeg/train/{}.jpg".format(self.base_path, name_image), "rb"))
        resized = image.resize((512, 512))
        tensored = transforms.ToTensor()(resized).unsqueeze_(0)
        return torch.reshape(tensored, (3, 512, 512))

    def get_metrics_dataloader(self):
        dataset = MelanomaRealHumanDataset(self.base_path, _delegate, self.batch_size)
        dataset.add_samples(self.x_metric, self.y_metric)
        return DataLoader(dataset, batch_size=self.batch_size)

    def add_samples(self, x, y):
        reshaped_x = []
        reshaped_y = []
        for i in range(len(x)):
            reshaped_x.append(x[i])
            reshaped_y.append(y[i])

        super().add_samples(reshaped_x, reshaped_y)

    def convert_sample(self, x, y=None):
        if isinstance(x, list):
            images = []
            targets = []
            for i in range(len(x)):
                image = self._extract_image(x[i])
                image = torch.reshape(image, (1, 3, 512, 512))
                images.append(image)
                if y is not None:
                    target = torch.tensor(y[i]).to(torch.float32)
                    targets.append(target)

            return images, targets

        else:
            return torch.reshape(self._extract_image(x), (1, 3, 512, 512)), torch.tensor(y).to(torch.float32)
