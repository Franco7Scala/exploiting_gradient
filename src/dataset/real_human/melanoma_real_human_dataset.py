import torch
import pandas
import random
import numpy

import PIL.Image
from dataset.abstract_human_dataset import AbstractHumanDataset
from torch.utils.data.dataloader import DataLoader
from torchvision.transforms import transforms


class MelanomaRealHumanDataset(AbstractHumanDataset):

    def __init__(self, base_path, batch_size=32):
        self.batch_size = batch_size
        self.base_path = base_path
        dataset_train = pandas.read_csv("{}train.csv".format(self.base_path), usecols=["image_name", "target"])
        x_labeled = []
        y_labeled = []
        x_unlabeled = []
        y_unlabeled = []
        x_metric = []
        y_metric = []
        x_dataset = []
        y_dataset = []
        for value in dataset_train.iterrows():
            x_dataset.append(value[1][0])
            y_dataset.append(value[1][1])


# TODO
        map_dataset = list(zip(x_dataset, y_dataset))
        random.shuffle(map_dataset)
        x_dataset, y_dataset = zip(*map_dataset)
        for i in range(total_labeled_samples_size + total_unlabeled_samples_size + total_test_samples_size):
            y = numpy.array([0, 1]) if y_dataset[i] == 0 else numpy.array([1, 0])
            if i < total_labeled_samples_size:
                x_labeled.append(x_dataset[i])
                y_labeled.append(y)

            elif total_labeled_samples_size < i < total_labeled_samples_size + total_unlabeled_samples_size:
                x_unlabeled.append(x_dataset[i])
                y_unlabeled.append(y)

            elif total_labeled_samples_size + total_unlabeled_samples_size < i < total_labeled_samples_size + total_unlabeled_samples_size + total_test_samples_size:
                x_metric.append(x_dataset[i])
                y_metric.append(y)

        super().__init__(x_labeled, y_labeled, x_unlabeled, y_unlabeled, x_metric, y_metric, batch_size)

    def __getitem__(self, index):
        return {"x": self._extract_image(self.x[index]), "y": self.y[index]}

    def annotate(self, x_to_label):
#TODO
        x_popped = []
        y_popped = []
        for key in x_to_label:
            x_popped.append(key)
            y_popped.append(self.unlabeled_elements.pop(key))

        return x_popped, y_popped

    def _extract_image(self, name_image):
        image = PIL.Image.open(open("{}jpeg/train/{}.jpg".format(self.base_path, name_image), "rb"))
        resized = image.resize((512, 512))
        tensored = transforms.ToTensor()(resized).unsqueeze_(0)
        return torch.reshape(tensored, (3, 512, 512))

    def get_metrics_dataloader(self):
        dataset = MelanomaRealHumanDataset(0, 0, 0, self.batch_size)
        dataset.add_samples(self.x_metric, self.y_metric)
        return DataLoader(dataset, batch_size=self.batch_size)

    def add_samples(self, x, y):
        reshaped_x = []
        reshaped_y = []
        for i in range(len(x)):
            reshaped_x.append(x[i])
            reshaped_y.append(y[i])

        super().add_samples(reshaped_x, reshaped_y)

    def convert_sample(self, x, y=None):
        if isinstance(x, list):
            images = []
            targets = []
            for i in range(len(x)):
                image = self._extract_image(x[i])
                image = torch.reshape(image, (1, 3, 512, 512))
                images.append(image)
                if y is not None:
                    target = torch.tensor(y[i]).to(torch.float32)
                    targets.append(target)

            return images, targets

        else:
            return torch.reshape(self._extract_image(x), (1, 3, 512, 512)), torch.tensor(y).to(torch.float32)
