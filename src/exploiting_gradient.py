import numpy
import time
import scipy.spatial

from technique_type import TechniqueType
from support import Color, cprint


def exploit_gradient(technique, quantity_samples_to_select, training_epochs, active_epochs, model, neural_network, dataset_fake_human, dataset_selector, features_extractor):
    # training the network on the known data (start dataset)
    global_start_time = time.time()
    if features_extractor is not None:
        cprint("Training feature extractor (vae)...", Color.GREEN)
        #TODO

    cprint("Training neural network...", Color.GREEN)
    start_time = time.time()
    neural_network.fit(dataset_fake_human.get_dataloader(), training_epochs)
    start_loss, start_accuracy = neural_network.get_statistics(dataset_fake_human.get_metrics_dataloader())
    end_time = time.time()
    cprint("Neural network first training time: {}".format(end_time - start_time), Color.LIGHT_GREEN)
    # training the network on the unknown datas (active learning dataset)
    cprint("Making Active Learning Training...", Color.GREEN)
    just_annotated_x, just_annotated_y = dataset_fake_human.get_random_labeled_samples(quantity_samples_to_select)
    dataset_fake_human.add_samples(just_annotated_x, just_annotated_y)
    cprint("Selector type: {}".format(technique), Color.BLUE)
    for a in range(active_epochs):
        if technique == TechniqueType.RANDOM or technique == TechniqueType.LEAST_CONFIDENCE:
            # training neural network with new samples
            cprint("Training network with new samples...", Color.GREEN)
            neural_network.fit(dataset_fake_human.get_dataloader(), training_epochs)
            end_time = time.time()
            cprint("Training time: {}".format(end_time - start_time), Color.LIGHT_GREEN)
            if technique == TechniqueType.RANDOM:
                just_annotated_x, just_annotated_y = dataset_fake_human.get_random_labeled_samples(quantity_samples_to_select)

            elif technique == TechniqueType.LEAST_CONFIDENCE:
                just_annotated_x, just_annotated_y = dataset_fake_human.get_least_confidence_labeled_samples(quantity_samples_to_select, neural_network)

        else:
            distances = numpy.zeros((len(just_annotated_x), training_epochs))
            for e in range(training_epochs):
                # building dataset for selector
                cprint("Training epoch n.{}...".format(e), Color.GREEN)
                start_time = time.time()
                start_gradients = []
                # iterating over all samples to take the initial gradient
                for index in range(len(just_annotated_x)):
                    # taking gradient for each sample and putting it in start_gradients[index]
                    if features_extractor is not None:
                        start_gradients.append(features_extractor.extract_features(just_annotated_x[index]))

                    else:
                        start_gradients.append(neural_network.extrapolate_single_gradient(just_annotated_x[index], just_annotated_y[index]))

                if technique == TechniqueType.SCORE_OTHER_DISTANCE or technique == TechniqueType.CLASS_OTHER_DISTANCE:
                    # taking gradient for each just annotated example wrt all other samples (to be optimized)
                    for s in range(len(just_annotated_x)):
                        current_gradient = neural_network.extrapolate_other_gradient(just_annotated_x, just_annotated_y, s)
                        distances[s, e] = abs(1 - scipy.spatial.distance.cosine(start_gradients[s], current_gradient))

                else:
                    # taking gradient for each just annotated example wrt single sample
                    current_gradient = neural_network.extrapolate_single_gradient(just_annotated_x, just_annotated_y)
                    # iterating over all samples to keep distances for each sample
                    for s in range(len(just_annotated_x)):
                        distances[s, e] = abs(1 - scipy.spatial.distance.cosine(start_gradients[s], current_gradient))

                # training neural network with new samples
                cprint("Training network with new samples...", Color.GREEN)
                neural_network.fit(dataset_fake_human.get_dataloader(), 1)
                end_time = time.time()
                cprint("Training epoch time: {}".format(end_time - start_time), Color.LIGHT_GREEN)

            for i in range(len(just_annotated_x)):
                # making average among the distances associated with the i-th example in the various epochs
                average = numpy.average(distances[i])
                # saving distance into dataset
                if technique == TechniqueType.SCORE_OTHER_DISTANCE or technique == TechniqueType.SCORE_SINGLE_DISTANCE:
                    dataset_selector.add_sample(just_annotated_x[i].tolist(), average)

                elif technique == TechniqueType.CLASS_OTHER_DISTANCE or technique == TechniqueType.CLASS_SINGLE_DISTANCE:
                    dataset_selector.add_sample(just_annotated_x[i].cpu().detach().numpy().reshape(1, -1), average)

            # training selector
            cprint("Training selector...", Color.GREEN)
            start_time = time.time()
            model_x, model_y = dataset_selector.get_train_dataset()
            model.fit(model_x, model_y)
            end_time = time.time()
            cprint("Training selector time: {}".format(end_time - start_time), Color.LIGHT_GREEN)

            cprint("Selecting next samples...", Color.GREEN)
            start_time = time.time()
            # labeling samples
            y = []
            x = dataset_fake_human.get_all_unlabeled_samples()
            for sample in x:
                y.append(model.predict(sample.cpu().detach().numpy().reshape(1, -1))[0])

            # selecting them
            selected = []
            if technique == TechniqueType.SCORE_SINGLE_DISTANCE or technique == TechniqueType.SCORE_OTHER_DISTANCE:
                for value in numpy.argsort(y)[-quantity_samples_to_select:][::-1]:
                    selected.append(x[value])

            else:
                selected_samples = 0
                for i, value in enumerate(y):
                    if numpy.argmax(y) == 2:
                        selected.append(x[i])
                        selected_samples += 1
                        if selected_samples >= quantity_samples_to_select:
                            break

            end_time = time.time()
            cprint("Selection time: {}".format(end_time - start_time), Color.LIGHT_GREEN)

            # make human label sampling
            cprint("Labeling samples...", Color.GREEN)
            start_time = time.time()
            just_annotated_x, just_annotated_y = dataset_fake_human.annotate(selected)
            dataset_fake_human.add_samples(just_annotated_x, just_annotated_y)
            end_time = time.time()
            cprint("Labeling time: {}".format(end_time - start_time), Color.LIGHT_GREEN)

    global_end_time = time.time()
    end_loss, end_accuracy = neural_network.get_statistics(dataset_fake_human.get_metrics_dataloader())
    return start_loss, start_accuracy, end_loss, end_accuracy, (global_end_time - global_start_time)
